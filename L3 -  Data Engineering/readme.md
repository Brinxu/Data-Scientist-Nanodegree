# Data Engineering

This file includes three subfiles, ETL Pipelines, NLP Pipeline, and Machine Learning Pipelines. 

## ETL Pipelines
I pull the data from different sources(i.e., csv, json, APIs), transform the data using various techniques, and load the transformed data into a data storage. Some of the transforming techniques I use include: 

- Data cleaning
- Change data types
- Parsing dates
- File encodings
- Deal with missing data
- Duplicate data
- Dummy variables
- Remove outliers
- Scaling features
- Engineering features

## NLP Pipeline 

- Text Processing
- Cleaning
- Normalization
- Tokenization
- Stop Word Removal
- Part of Speech Tagging
- Named Entity Recognition
- Stemming and Lemmatization
- Feature Extraction
- Bag of Words
- TF-IDF
- Word Embeddings
- Modeling

## Machine Learning Pipelines

- Scikit-learn Pipeline
- Scikit-learn Feature Union
- Pipelines and Grid Search

## Data
Related data used in codings can be found [here](https://drive.google.com/drive/folders/16QPqSAll76gNdLGljKw6KpGO_qAMM_79?usp=sharing). 

## Project
A project that implemented all the above techniques can be found [here](https://github.com/Brinxu/Disaster-Response-Pipeline). 
